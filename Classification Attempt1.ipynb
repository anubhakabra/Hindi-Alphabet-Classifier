{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubha\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubha\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from os import listdir\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras.constraints import maxnorm\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using OpenCV library of python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#With just image flatened\n",
    "def image_to_feature_vector(image, size=(128, 128)):\n",
    "\t# resize the image to a fixed size, then flatten the image into\n",
    "\t# a list of raw pixel intensities\n",
    "\treturn cv2.resize(image, size).flatten()\n",
    "\n",
    "#With histogram graph plot of image , normalised \n",
    "def extract_color_histogram(image, bins=(32, 32, 32)):\n",
    "\t# extract a 3D color histogram from the HSV color space using\n",
    "\t# the supplied number of `bins` per channel\n",
    "\thsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\thist = cv2.calcHist([hsv], [0, 1, 2], None, bins,\n",
    "\t\t[0, 180, 0, 256, 0, 256])\n",
    "\n",
    "\t# handle normalizing the histogram if we are using OpenCV 2.4.X\n",
    "\tif imutils.is_cv2():\n",
    "\t\thist = cv2.normalize(hist)\n",
    "\n",
    "\t# otherwise, perform \"in place\" normalization in OpenCV 3\n",
    "\telse:\n",
    "\t\tcv2.normalize(hist, hist)\n",
    "\n",
    "\t# return the flattened histogram as the feature vector\n",
    "\treturn hist.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_folder=['character_1_ka','character_2_kha','character_3_ga','character_4_gha','character_5_kna']\n",
    "#Label = ['Ka','Kha','Ga','Gha','Kna']\n",
    "Labels = [0,1,2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubha\\Desktop\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Images: 8500\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "def load_photos(train_data_folder,Desktop):\n",
    "    i=0\n",
    "    y=[]\n",
    "    images=[]\n",
    "    rawImages = []\n",
    "    features = []\n",
    "    for directory in train_data_folder:\n",
    "        y_val=Labels[i]\n",
    "        \n",
    "        for name in listdir(Desktop+'/'+ directory):\n",
    "            # load an image from file\n",
    "            filename = Desktop+'/'+directory + '/' + name\n",
    "            image = cv2.imread(filename) #target_size=(32, 32,1))\n",
    "            # convert the image pixels to a numpy array\n",
    "            pixels = image_to_feature_vector(image)\n",
    "            hist = extract_color_histogram(image)\n",
    "\n",
    "            rawImages.append(pixels)\n",
    "            features.append(hist)\n",
    "            #labels.append(label)\n",
    "            y.append(y_val)\n",
    "        i=i+1;\n",
    "    return rawImages,features,y\n",
    "\n",
    "# load images\n",
    "Train_Desktop = 'Train_val'\n",
    "rawimages,features,y = load_photos(train_data_folder,Train_Desktop)\n",
    "print('Loaded Images: %d' % len(rawimages))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting in numpy array\n",
    "rawImages = np.array(rawimages)\n",
    "features = np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8500"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] pixels matrix: 408.00MB\n",
      "[INFO] features matrix: 1088.00MB\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] pixels matrix: {:.2f}MB\".format(\n",
    "\trawImages.nbytes / (1024 * 1000.0)))\n",
    "print(\"[INFO] features matrix: {:.2f}MB\".format(\n",
    "\tfeatures.nbytes / (1024 * 1000.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Images Test: 1500\n"
     ]
    }
   ],
   "source": [
    "Desktop_test = 'Test'\n",
    "rawimages_y,features_y,y_y = load_photos(train_data_folder,Desktop_test)\n",
    "print('Loaded Images Test: %d' % len(rawimages_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8500"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test features : raw and histogram version\n",
    "rawImages_y = np.array(rawimages_y)\n",
    "features_y = np.array(features_y)\n",
    "labels_y= np.array(y_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffling data : Histogram Train Data\n",
    "f = np.c_[features.reshape(len(features), -1), labels.reshape(len(labels), -1)]\n",
    "np.random.shuffle(f)\n",
    "\n",
    "features1 = f[:, :features.size//len(features)].reshape(features.shape)\n",
    "labels_f1 = f[:, features.size//len(features):].reshape(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffling Test Histogram data\n",
    "fy = np.c_[features_y.reshape(len(features_y), -1), labels_y.reshape(len(labels_y), -1)]\n",
    "np.random.shuffle(fy)\n",
    "\n",
    "features_y1 = fy[:, :features_y.size//len(features_y)].reshape(features_y.shape)\n",
    "labels_fy1 = fy[:, features_y.size//len(features_y):].reshape(labels_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffling Train Raw Image data\n",
    "c = np.c_[rawImages.reshape(len(rawImages), -1), labels.reshape(len(labels), -1)]\n",
    "np.random.shuffle(c)\n",
    "\n",
    "rawImages1 = c[:, :rawImages.size//len(rawImages)].reshape(rawImages.shape)\n",
    "labels1 = c[:, rawImages.size//len(rawImages):].reshape(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffling Test Raw Image data\n",
    "cy = np.c_[rawImages_y.reshape(len(rawImages_y), -1), labels_y.reshape(len(labels_y), -1)]\n",
    "np.random.shuffle(cy)\n",
    "\n",
    "rawImages_y1 = cy[:, :rawImages_y.size//len(rawImages_y)].reshape(rawImages_y.shape)\n",
    "labels_y1 = cy[:, rawImages_y.size//len(rawImages_y):].reshape(labels_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8500 8500 8500\n"
     ]
    }
   ],
   "source": [
    "print(len(rawImages),len(rawImages1),len(features1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[INFO] evaluating raw pixel accuracy...\n",
      "[INFO] neural network raw pixel accuracy: 20.00%\n",
      "\n",
      "\n",
      "[INFO] evaluating histogram accuracy...\n",
      "[INFO] neural network histogram accuracy: 36.47%\n"
     ]
    }
   ],
   "source": [
    "#neural network\n",
    "print(\"\\n\")\n",
    "print(\"[INFO] evaluating raw pixel accuracy...\")\n",
    "model = MLPClassifier(hidden_layer_sizes=(50,), max_iter=1000, alpha=1e-4,\n",
    "                      solver='sgd', tol=1e-4, random_state=1,\n",
    "                      learning_rate_init=.1)\n",
    "model.fit(rawImages1, labels1)\n",
    "acc = model.score(rawImages_y1, labels_y1)\n",
    "print(\"[INFO] neural network raw pixel accuracy: {:.2f}%\".format(acc * 100))\n",
    "\n",
    "\n",
    "#neural network\n",
    "print(\"\\n\")\n",
    "print(\"[INFO] evaluating histogram accuracy...\")\n",
    "model = MLPClassifier(hidden_layer_sizes=(50,), max_iter=1000, alpha=1e-4,\n",
    "                      solver='sgd', tol=1e-4, random_state=1,\n",
    "                      learning_rate_init=.1)\n",
    "model.fit(features1, labels_f1)\n",
    "acc = model.score(features_y1, labels_fy1)\n",
    "print(\"[INFO] neural network histogram accuracy: {:.2f}%\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[INFO] evaluating raw pixel accuracy...\n",
      "[INFO] neural network raw pixel accuracy: 98.87%\n",
      "\n",
      "\n",
      "[INFO] evaluating histogram accuracy...\n",
      "[INFO] neural network histogram accuracy: 38.33%\n"
     ]
    }
   ],
   "source": [
    "# k-NN\n",
    "print(\"\\n\")\n",
    "print(\"[INFO] evaluating raw pixel accuracy...\")\n",
    "model = KNeighborsClassifier(n_neighbors=5)\n",
    "model.fit(rawImages1, labels1)\n",
    "acc = model.score(rawImages_y1, labels_y1)\n",
    "\n",
    "#either faulty or exceptional \n",
    "print(\"[INFO] neural network raw pixel accuracy: {:.2f}%\".format(acc * 100))\n",
    "\n",
    "# k-NN\n",
    "print(\"\\n\")\n",
    "print(\"[INFO] evaluating histogram accuracy...\")\n",
    "model = KNeighborsClassifier(n_neighbors=5)\n",
    "model.fit(features1, labels_f1)\n",
    "acc = model.score(features_y1, labels_fy1)\n",
    "print(\"[INFO] neural network histogram accuracy: {:.2f}%\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[INFO] evaluating raw pixel accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubha\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] SVM-SVC raw pixel accuracy: 20.00%\n",
      "\n",
      "\n",
      "[INFO] evaluating histogram accuracy...\n",
      "[INFO] SVM-SVC histogram accuracy: 21.87%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#SVC\n",
    "print(\"\\n\")\n",
    "print(\"[INFO] evaluating raw pixel accuracy...\")\n",
    "model = SVC(max_iter=1000,class_weight='balanced')\n",
    "model.fit(rawImages1, labels1)\n",
    "acc = model.score(rawImages_y1, labels_y1)\n",
    "print(\"[INFO] SVM-SVC raw pixel accuracy: {:.2f}%\".format(acc * 100))\n",
    "#SVC\n",
    "print(\"\\n\")\n",
    "print(\"[INFO] evaluating histogram accuracy...\")\n",
    "#default kernel RBS\n",
    "model = SVC(max_iter=1000,class_weight='balanced')\n",
    "model.fit(features1, labels_f1)\n",
    "acc = model.score(features_y1, labels_fy1)\n",
    "print(\"[INFO] SVM-SVC histogram accuracy: {:.2f}%\".format(acc * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
