{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Images: 8500\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 30, 30, 128)       3584      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 28800)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               3686528   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 3,690,757\n",
      "Trainable params: 3,690,757\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/15\n",
      "266/265 [==============================] - 117s 440ms/step - loss: 0.7662 - acc: 0.7115\n",
      "Epoch 2/15\n",
      "266/265 [==============================] - 149s 559ms/step - loss: 0.4334 - acc: 0.8514\n",
      "Epoch 3/15\n",
      "266/265 [==============================] - 188s 706ms/step - loss: 0.3448 - acc: 0.8800\n",
      "Epoch 4/15\n",
      "266/265 [==============================] - 188s 708ms/step - loss: 0.3066 - acc: 0.8991\n",
      "Epoch 5/15\n",
      "266/265 [==============================] - 188s 707ms/step - loss: 0.2783 - acc: 0.9072\n",
      "Epoch 6/15\n",
      "266/265 [==============================] - 187s 703ms/step - loss: 0.2583 - acc: 0.9154\n",
      "Epoch 7/15\n",
      "266/265 [==============================] - 191s 718ms/step - loss: 0.2416 - acc: 0.9207\n",
      "Epoch 8/15\n",
      "266/265 [==============================] - 188s 705ms/step - loss: 0.2275 - acc: 0.9253\n",
      "Epoch 9/15\n",
      "266/265 [==============================] - 186s 699ms/step - loss: 0.2184 - acc: 0.9270\n",
      "Epoch 10/15\n",
      "266/265 [==============================] - 186s 700ms/step - loss: 0.2091 - acc: 0.9320\n",
      "Epoch 11/15\n",
      "266/265 [==============================] - 186s 699ms/step - loss: 0.2019 - acc: 0.9344\n",
      "Epoch 12/15\n",
      "266/265 [==============================] - 185s 696ms/step - loss: 0.1961 - acc: 0.9354\n",
      "Epoch 13/15\n",
      "266/265 [==============================] - 185s 696ms/step - loss: 0.1809 - acc: 0.9403\n",
      "Epoch 14/15\n",
      "266/265 [==============================] - 185s 696ms/step - loss: 0.1804 - acc: 0.9421\n",
      "Epoch 15/15\n",
      "266/265 [==============================] - 187s 702ms/step - loss: 0.1725 - acc: 0.9432\n",
      "Loaded Images Test: 1500\n",
      "Accuracy with ADAM for Model 0 :  0.9633333336512248\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from os import listdir\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras.constraints import maxnorm\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "train_data_folder=['character_1_ka','character_2_kha','character_3_ga','character_4_gha','character_5_kna']\n",
    "Label = ['Ka','Kha','Ga','Gha','Kna']\n",
    "Labels = [0,1,2,3,4]\n",
    "\n",
    "\n",
    "# In[19]:\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def load_photos(train_data_folder,Desktop):\n",
    "    i=0\n",
    "    y=[]\n",
    "    images=[]\n",
    "    for directory in train_data_folder:\n",
    "        y_val=Labels[i]\n",
    "        \n",
    "        for name in listdir(Desktop+'/'+ directory):\n",
    "            # load an image from file\n",
    "            filename = Desktop+'/'+directory + '/' + name\n",
    "            image = load_img(filename) #target_size=(32, 32,1))\n",
    "            # convert the image pixels to a numpy array\n",
    "            image = img_to_array(image)\n",
    "            # reshape data for the model\n",
    "            image = image.reshape((image.shape[0], image.shape[1], image.shape[2]))\n",
    "            # prepare the image for the VGG model\n",
    "            image = preprocess_input(image)\n",
    "            # get image id\n",
    "            #image_id = name.split('.')[0]\n",
    "            images.append(image)\n",
    "            y.append(y_val)\n",
    "        i=i+1;\n",
    "    return images,y\n",
    "\n",
    "# load images\n",
    "Train_Desktop = 'Train_val'\n",
    "images,y = load_photos(train_data_folder,Train_Desktop)\n",
    "print('Loaded Images: %d' % len(images))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "x_train = np.asarray(images)\n",
    "y_train = np.asarray(y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "featurewise_center=True,\n",
    "featurewise_std_normalization=True,\n",
    "rotation_range=20,\n",
    "width_shift_range=0.2,\n",
    "height_shift_range=0.2,\n",
    "horizontal_flip=True)\n",
    "\n",
    "datagen.fit(x_train)\n",
    "input_shape = (32, 32, 3)\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "# Creating a Sequential Model and adding the layers\n",
    "model = Sequential()\n",
    "model.add(Conv2D(128, kernel_size=(3,3), input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation=tf.nn.relu))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(5,activation=tf.nn.softmax))\n",
    "\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=128),\n",
    "                    steps_per_epoch=len(x_train) / 32, epochs=15,shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "Desktop_test = 'Test'\n",
    "images_test,y_test = load_photos(train_data_folder,Desktop_test)\n",
    "print('Loaded Images Test: %d' % len(images_test))\n",
    "import numpy as np\n",
    "x_test = np.asarray(images_test)\n",
    "y_test = np.asarray(y_test)\n",
    "x_test = x_test / 255.0\n",
    "datagen.fit(x_test)\n",
    "\n",
    "\n",
    "# In[23]:\n",
    "\n",
    "\n",
    "score_ADAM = model.evaluate_generator(datagen.flow(x_test, y_test, batch_size=32),steps=len(x_test)/32 )\n",
    "print (\"Accuracy with ADAM for Model 0 : \" , score_ADAM[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
