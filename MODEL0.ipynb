{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubha\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras as kr\n",
    "from keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubha\\Desktop\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_folder=['character_1_ka','character_2_kha','character_3_ga','character_4_gha','character_5_kna']\n",
    "Label = ['Ka','Kha','Ga','Gha','Kna']\n",
    "Labels = [0,1,2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Images: 8500\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "def load_photos(train_data_folder,Desktop):\n",
    "    i=0\n",
    "    y=[]\n",
    "    images=[]\n",
    "    for directory in train_data_folder:\n",
    "        y_val=Labels[i]\n",
    "        \n",
    "        for name in listdir(Desktop+'/'+ directory):\n",
    "            # load an image from file\n",
    "            filename = Desktop+'/'+directory + '/' + name\n",
    "            image = load_img(filename) #target_size=(32, 32,1))\n",
    "            # convert the image pixels to a numpy array\n",
    "            image = img_to_array(image)\n",
    "            # reshape data for the model\n",
    "            image = image.reshape((image.shape[0], image.shape[1], image.shape[2]))\n",
    "            # prepare the image for the VGG model\n",
    "            image = preprocess_input(image)\n",
    "\n",
    "            images.append(image)\n",
    "            y.append(y_val)\n",
    "        i=i+1;\n",
    "    return images,y\n",
    "\n",
    "# load images\n",
    "Train_Desktop = 'Train_val'\n",
    "images,y = load_photos(train_data_folder,Train_Desktop)\n",
    "print('Loaded Images: %d' % len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubha\\Desktop\\Train_val\n"
     ]
    }
   ],
   "source": [
    "cd Desktop\\Train_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x_train = np.asarray(images)\n",
    "y_train = np.asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "y_train=y_train.reshape(8500,1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "featurewise_center=True,\n",
    "featurewise_std_normalization=True,\n",
    "rotation_range=20,\n",
    "width_shift_range=0.2,\n",
    "height_shift_range=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (32, 32, 3)\n",
    "# Making sure that the values are float so that we can get decimal points after division\n",
    "x_train = x_train.astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "# Creating a Sequential Model and adding the layers\n",
    "model = Sequential()\n",
    "model.add(Conv2D(128, kernel_size=(3,3), input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation=tf.nn.relu))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(5,activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 30, 30, 128)       3584      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 15, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 28800)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               3686528   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 3,690,757\n",
      "Trainable params: 3,690,757\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "266/265 [==============================] - 109s 411ms/step - loss: 1.0807 - acc: 0.5807\n",
      "Epoch 2/32\n",
      "266/265 [==============================] - 104s 390ms/step - loss: 0.6725 - acc: 0.7594\n",
      "Epoch 3/32\n",
      "266/265 [==============================] - 105s 395ms/step - loss: 0.5577 - acc: 0.8079\n",
      "Epoch 4/32\n",
      "266/265 [==============================] - 106s 398ms/step - loss: 0.5061 - acc: 0.8269\n",
      "Epoch 5/32\n",
      "266/265 [==============================] - 105s 396ms/step - loss: 0.4585 - acc: 0.8501\n",
      "Epoch 6/32\n",
      "266/265 [==============================] - 105s 395ms/step - loss: 0.4402 - acc: 0.8541\n",
      "Epoch 7/32\n",
      "266/265 [==============================] - 107s 402ms/step - loss: 0.4162 - acc: 0.8667\n",
      "Epoch 8/32\n",
      "266/265 [==============================] - 106s 397ms/step - loss: 0.3842 - acc: 0.8726\n",
      "Epoch 9/32\n",
      "266/265 [==============================] - 108s 405ms/step - loss: 0.3583 - acc: 0.8756\n",
      "Epoch 10/32\n",
      "266/265 [==============================] - 106s 398ms/step - loss: 0.3845 - acc: 0.8769\n",
      "Epoch 11/32\n",
      "266/265 [==============================] - 108s 408ms/step - loss: 0.3464 - acc: 0.8833\n",
      "Epoch 12/32\n",
      "266/265 [==============================] - 116s 436ms/step - loss: 0.3333 - acc: 0.8883\n",
      "Epoch 13/32\n",
      "266/265 [==============================] - 158s 592ms/step - loss: 0.3287 - acc: 0.8905\n",
      "Epoch 14/32\n",
      "266/265 [==============================] - 160s 600ms/step - loss: 0.3122 - acc: 0.8998\n",
      "Epoch 15/32\n",
      "266/265 [==============================] - 123s 461ms/step - loss: 0.3091 - acc: 0.8972\n",
      "Epoch 16/32\n",
      "266/265 [==============================] - 109s 412ms/step - loss: 0.3076 - acc: 0.8984\n",
      "Epoch 17/32\n",
      "266/265 [==============================] - 108s 407ms/step - loss: 0.3110 - acc: 0.8999\n",
      "Epoch 18/32\n",
      "266/265 [==============================] - 108s 407ms/step - loss: 0.2948 - acc: 0.9063\n",
      "Epoch 19/32\n",
      "266/265 [==============================] - 109s 411ms/step - loss: 0.2863 - acc: 0.9074\n",
      "Epoch 20/32\n",
      "266/265 [==============================] - 108s 407ms/step - loss: 0.2731 - acc: 0.9098\n",
      "Epoch 21/32\n",
      "266/265 [==============================] - 117s 442ms/step - loss: 0.2812 - acc: 0.9103\n",
      "Epoch 22/32\n",
      "266/265 [==============================] - 95s 359ms/step - loss: 0.2908 - acc: 0.9072\n",
      "Epoch 23/32\n",
      "266/265 [==============================] - 72s 272ms/step - loss: 0.2805 - acc: 0.9095\n",
      "Epoch 24/32\n",
      "266/265 [==============================] - 69s 261ms/step - loss: 0.2488 - acc: 0.9203\n",
      "Epoch 25/32\n",
      "266/265 [==============================] - 77s 289ms/step - loss: 0.2663 - acc: 0.9152\n",
      "Epoch 26/32\n",
      "266/265 [==============================] - 80s 302ms/step - loss: 0.2572 - acc: 0.9175\n",
      "Epoch 27/32\n",
      "266/265 [==============================] - 98s 369ms/step - loss: 0.2567 - acc: 0.9197\n",
      "Epoch 28/32\n",
      "266/265 [==============================] - 100s 378ms/step - loss: 0.2619 - acc: 0.9121\n",
      "Epoch 29/32\n",
      "266/265 [==============================] - 98s 367ms/step - loss: 0.2571 - acc: 0.9197\n",
      "Epoch 30/32\n",
      "266/265 [==============================] - 99s 371ms/step - loss: 0.2524 - acc: 0.9196\n",
      "Epoch 31/32\n",
      "266/265 [==============================] - 98s 369ms/step - loss: 0.2442 - acc: 0.9218\n",
      "Epoch 32/32\n",
      "266/265 [==============================] - 72s 271ms/step - loss: 0.2708 - acc: 0.9164\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c73391b588>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=32),\n",
    "                    steps_per_epoch=len(x_train) / 32, epochs=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Images Test: 1500\n"
     ]
    }
   ],
   "source": [
    "Desktop_test = 'Test'\n",
    "images_test,y_test = load_photos(train_data_folder,Desktop_test)\n",
    "print('Loaded Images Test: %d' % len(images_test))\n",
    "import numpy as np\n",
    "x_test = np.asarray(images_test)\n",
    "y_test = np.asarray(y_test)\n",
    "x_test = x_test / 255.0\n",
    "datagen.fit(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with ADAM for Model 0 :  0.9586666666666667\n"
     ]
    }
   ],
   "source": [
    "score_ADAM = model.evaluate_generator(datagen.flow(x_test, y_test, batch_size=32),steps=len(x_test)/32 )\n",
    "print (\"Accuracy with ADAM for Model 0 : \" , score_ADAM[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
