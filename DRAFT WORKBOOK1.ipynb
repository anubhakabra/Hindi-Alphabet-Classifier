{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubha\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras as kr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubha\n"
     ]
    }
   ],
   "source": [
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubha\\Desktop\n"
     ]
    }
   ],
   "source": [
    "cd Desktop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubha\\Desktop\\Train_val\n"
     ]
    }
   ],
   "source": [
    "cd Train_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_folder=['character_1_ka','character_2_kha','character_3_ga','character_4_gha','character_5_kna']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "Label = ['Ka','Kha','Ga','Gha','Kna']\n",
    "Labels = [0,1,2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Images: 8500\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "images=[]\n",
    "y_train=[]\n",
    "i=0\n",
    "\n",
    "    \n",
    "def load_photos(train_data_folder):\n",
    "    i=0\n",
    "    y=[]\n",
    "    for directory in train_data_folder:\n",
    "        y_val=Labels[i]\n",
    "        \n",
    "        for name in listdir(directory):\n",
    "            # load an image from file\n",
    "            filename = directory + '/' + name\n",
    "            image = load_img(filename)\n",
    "            # convert the image pixels to a numpy array\n",
    "            image = img_to_array(image)\n",
    "            # reshape data for the model\n",
    "            image = image.reshape((image.shape[0], image.shape[1], image.shape[2]))\n",
    "            \n",
    "            # prepare the image for the VGG model\n",
    "            image = preprocess_input(image)\n",
    "            # get image id\n",
    "            #image_id = name.split('.')[0]\n",
    "            images.append(image)\n",
    "            y.append(y_val)\n",
    "        i=i+1;\n",
    "    return images,y\n",
    "\n",
    "# load images\n",
    "\n",
    "images,y = load_photos(train_data_folder)\n",
    "print('Loaded Images: %d' % len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8500"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x_train = np.asarray(images)\n",
    "y_train = np.asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "y_train=y_train.reshape(8500,1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen.fit(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "266/265 [==============================] - 273s 1s/step - loss: 0.5781 - acc: 0.8016\n",
      "Epoch 2/10\n",
      "266/265 [==============================] - 265s 997ms/step - loss: 0.5750 - acc: 0.8028\n",
      "Epoch 3/10\n",
      "266/265 [==============================] - 132s 497ms/step - loss: 0.5543 - acc: 0.8115\n",
      "Epoch 4/10\n",
      "266/265 [==============================] - 107s 402ms/step - loss: 0.5741 - acc: 0.7979\n",
      "Epoch 5/10\n",
      "266/265 [==============================] - 110s 413ms/step - loss: 0.5715 - acc: 0.8030\n",
      "Epoch 6/10\n",
      "266/265 [==============================] - 101s 381ms/step - loss: 0.5577 - acc: 0.8075\n",
      "Epoch 7/10\n",
      "266/265 [==============================] - 103s 387ms/step - loss: 0.5370 - acc: 0.8157\n",
      "Epoch 8/10\n",
      "266/265 [==============================] - 97s 364ms/step - loss: 0.5433 - acc: 0.8130\n",
      "Epoch 9/10\n",
      "266/265 [==============================] - 102s 382ms/step - loss: 0.5337 - acc: 0.8202\n",
      "Epoch 10/10\n",
      "266/265 [==============================] - 101s 379ms/step - loss: 0.5313 - acc: 0.8200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22e73d29a20>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=32),\n",
    "                    steps_per_epoch=len(x_train) / 32, epochs=10,shuffle =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (32, 32, 3)\n",
    "# Making sure that the values are float so that we can get decimal points after division\n",
    "x_train = x_train.astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "X_train,Y_train = shuffle(x_train,y_train,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required Keras modules containing model and layers\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "# Creating a Sequential Model and adding the layers\n",
    "model = Sequential()\n",
    "model.add(Conv2D(128, kernel_size=(3,3), input_shape=input_shape))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Flatten()) # Flattening the 2D arrays for fully connected layers\n",
    "#model.add(Dense(128, activation=tf.nn.relu,input_shape=input_shape))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation=tf.nn.relu))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(5,activation=tf.nn.softmax))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 30, 30, 128)       3584      \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 115200)            0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 128)               14745728  \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 14,749,957\n",
      "Trainable params: 14,749,957\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6800 samples, validate on 1700 samples\n",
      "Epoch 1/10\n",
      "6800/6800 [==============================] - 92s 13ms/step - loss: 10.0389 - acc: 0.3754 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "6800/6800 [==============================] - 39s 6ms/step - loss: 10.1593 - acc: 0.3696 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "6800/6800 [==============================] - 42s 6ms/step - loss: 9.1146 - acc: 0.4344 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "6800/6800 [==============================] - 40s 6ms/step - loss: 9.4416 - acc: 0.4141 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "6800/6800 [==============================] - 40s 6ms/step - loss: 9.6187 - acc: 0.4032 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "6800/6800 [==============================] - 42s 6ms/step - loss: 9.6187 - acc: 0.4032 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "6800/6800 [==============================] - 41s 6ms/step - loss: 9.6187 - acc: 0.4032 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "6800/6800 [==============================] - 42s 6ms/step - loss: 9.6187 - acc: 0.4032 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "6800/6800 [==============================] - 41s 6ms/step - loss: 9.6187 - acc: 0.4032 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "6800/6800 [==============================] - 73s 11ms/step - loss: 9.6187 - acc: 0.4032 - val_loss: 16.1181 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22e70d51b70>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "model.fit(x=x_train,y=y_train, epochs=10, batch_size=128, validation_split =0.2,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Images: 1500\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "images=[]\n",
    "y_train=[]\n",
    "i=0\n",
    "\n",
    "\n",
    "def load_photos(train_data_folder):\n",
    "    i=0\n",
    "    y=[]\n",
    "   # cd Test\n",
    "    for directory in train_data_folder:\n",
    "        y_val=Labels[i]\n",
    "        \n",
    "        for name in listdir('Test'+'/' +directory):\n",
    "            # load an image from file\n",
    "            filename = 'Test'+'/' +directory + '/' + name\n",
    "            image = load_img(filename)\n",
    "            # convert the image pixels to a numpy array\n",
    "            image = img_to_array(image)\n",
    "            # reshape data for the model\n",
    "            image = image.reshape((image.shape[0], image.shape[1], image.shape[2]))\n",
    "            \n",
    "            # prepare the image for the VGG model\n",
    "            image = preprocess_input(image)\n",
    "            # get image id\n",
    "            #image_id = name.split('.')[0]\n",
    "            images.append(image)\n",
    "            y.append(y_val)\n",
    "        i=i+1;\n",
    "    return images,y\n",
    "\n",
    "# load images\n",
    "\n",
    "images_test,y_test = load_photos(train_data_folder)\n",
    "print('Loaded Images: %d' % len(images_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x_test = np.asarray(images_test)\n",
    "y_test = np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 4s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[10.874341775258372, 0.3253333333333333]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
